model_name: "EDEN_VAE"
mixed_precision: "no"
model_args:
  in_dim: 3
  out_dim: 3
  patch_size: 16
  hidden_dim: 768
  num_heads: 12
  mlp_ratio: 4.
  latent_dim: 16
  encoder_depth: 4
  decoder_depth: 4
  qkv_bias: false
  attn_drop_rate: 0.
  proj_drop_rate: 0.
  use_xformers: true
  add_attn_encoder: true
  add_attn_decoder: true
  add_attn_type: "temporal_attn"
dataset_name: "LAVIB"
val_dataset_name: "DAVIS"
dataset_args:
  LAVIB:
    split_name: "train"
    data_dir: datasets/LAVIB
    height: 256
    width: 448
    dur_list: [3, 5, 7]
    dur_weights: [1.0, 0.0, 0.0]
  DAVIS:
    data_dir: datasets/DAVIS
    height: 256
    width: 448
    is_val: true
dataloader:
  batch_size: 32
  shuffle: true
  drop_last: true
  num_workers: 8
val_dataloader:
  batch_size: 32
  num_workers: 8
output_dir: output # experiment outputs dir
global_seed: 0
train_args:
  resume_from_ckpt: null  # pretrained vae ckpt path and pretrained discriminator ckpt path
  epochs: 100
  base_lr: 1.25e-05
  optimizer:
    weight_decay: 1.0e-4
    betas: [0.9, 0.99]
    eps: 1.0e-06
  lr_scheduler: "cosine"
  warmup_steps: 100
  log_every_steps: 10
  ckpt_every_steps: 2000
  visual_every_steps: 2000
  visual_results_num: 4
  val_every_steps: 2000
  val_metric: "PSNR"
  loss:
    disc_start: 50001
    perceptual_weight: 1.0
    disc_weight: 0.5
    kl_weight: 1.0e-06